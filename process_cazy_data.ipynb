{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "import bioservices\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Using BioServices, rather than a manual online search to get data\n",
    "from bioservices import UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using UniProt BioServices to get data, rather than manual search\n",
    "u = UniProt()\n",
    "#result = u.get_df('database:(type:cazy) AND taxonomy:\"Dickeya [204037]\"')\n",
    "query_result = u.search('database:(type:cazy) AND taxonomy:\"Dickeya [204037]\"',\n",
    "                  frmt='tab',\n",
    "                  columns=\"id, entry name, genes(OLN), protein names, database(CAZy), sequence\")\n",
    "result = pd.read_csv(StringIO(query_result), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all proteins without a locus tag\n",
    "nolocus = result[pd.isnull(result[\"Gene names  (ordered locus )\"])]\n",
    "nolocus = nolocus.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all proteins with a locus tag\n",
    "locus = result[pd.notnull(result[\"Gene names  (ordered locus )\"])]\n",
    "locus = locus.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write sequences with no locus tag to FASTA file\n",
    "seqlist = list()\n",
    "for idx, entry in result[pd.isnull(result[\"Gene names  (ordered locus )\"])].iterrows():\n",
    "    seqlist.append(SeqRecord(id=entry[\"Entry name\"],\n",
    "                             description=entry[\"Protein names\"],\n",
    "                             seq=Seq(entry[\"Sequence\"])))\n",
    "#SeqIO.write(seqlist, \"all_uniprot_nolocus_results.fasta\", \"fasta\")\n",
    "shutil.move(\"./all_uniprot_nolocus_results.fasta\", \"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_cazy_families(df):\n",
    "    \"\"\"Returns a DataFrame with one CAZy family per row.\n",
    "    UniProt sequences will be duplicated, where they are members of more than one family\n",
    "    \"\"\"\n",
    "    df = df.reset_index()\n",
    "    for idx, entry in df.iterrows():\n",
    "        cazy_families = [e for e in entry[\"Cross-reference (CAZy)\"].strip().split(';') if e]\n",
    "        df.set_value(idx, \"Cross-reference (CAZy)\", cazy_families[0])\n",
    "        if len(cazy_families) > 1:\n",
    "            for family in cazy_families[1:]:\n",
    "                new_entry = entry.copy()\n",
    "                new_entry[\"Cross-reference (CAZy)\"] = family\n",
    "                df = df.append(new_entry, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nolocus_split = split_cazy_families(result[pd.isnull(result[\"Gene names  (ordered locus )\"])])\n",
    "locus_split = split_cazy_families(result[pd.notnull(result[\"Gene names  (ordered locus )\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write nolocus seq for all families out in different files names $FAMILY_nolocus.fasta\n",
    "outdir = 'nolocus_sequences'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "for family in nolocus_split[\"Cross-reference (CAZy)\"].unique():\n",
    "    nolocus_family_seq = list()\n",
    "    for idx, entry in nolocus_split[nolocus_split[\"Cross-reference (CAZy)\"] == family].iterrows():\n",
    "        nolocus_family_seq.append(SeqRecord(id=entry[\"Entry name\"],\n",
    "                             description=entry[\"Protein names\"],\n",
    "                             seq=Seq(entry[\"Sequence\"])))\n",
    "    #print(nolocus_family_seq)\n",
    "    filename = os.path.join(outdir, \"{0}_nolocus.fasta\".format(family))\n",
    "    #SeqIO.write(nolocus_family_seq, filename, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write nolocus seq for all families out in different files names $FAMILY_nolocus.fasta\n",
    "outdir = './locus_sequences'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "for family in locus_split[\"Cross-reference (CAZy)\"].unique():\n",
    "    locus_family_seq = list()\n",
    "    for idx, entry in locus_split[locus_split[\"Cross-reference (CAZy)\"] == family].iterrows():\n",
    "        locus_family_seq.append(SeqRecord(id=entry[\"Entry name\"],\n",
    "                             description=entry[\"Protein names\"],\n",
    "                             seq=Seq(entry[\"Sequence\"])))\n",
    "    #print(nolocus_family_seq)\n",
    "    filename = os.path.join(outdir, \"{0}_nolocus.fasta\".format(family))\n",
    "    #SeqIO.write(locus_family_seq, filename, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shutil.move(\"./locus_sequences/\", \"../data\")\n",
    "shutil.move(\"./nolocus_sequences/\", \"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the entries with two or mores values for CAZy and parsing into string\n",
    "countdf = locus_split.groupby(\"Gene names  (ordered locus )\").count()\n",
    "result = locus_split.loc[locus_split[\"Gene names  (ordered locus )\"].isin(countdf[countdf[\"Cross-reference (CAZy)\"] > 1].index)]\n",
    "resultlist = result.groupby(\"Gene names  (ordered locus )\")[\"Cross-reference (CAZy)\"].apply(list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  We turn into a list the dataframe for the nolocus tag so we can get the Uniprpot accession numbers of those seqs\n",
    "no_locus_list = nolocus['Entry'].tolist()\n",
    "\n",
    "# Write in a text file the uniprot accessions fro sequences with no locus tags\n",
    "with open('uniprot_no_locus.txt', 'w') as file_handler:\n",
    "    for i in no_locus_list:\n",
    "        file_handler.write(\"{}\\n\".format(i))\n",
    "shutil.move(\"./uniprot_no_locus.txt\", \"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  We turn into the list the dataframe for the locus tag so we can get the the locus tags for the RBBH analysis\n",
    "locus_tags_list = locus_split[\"Gene names  (ordered locus )\"].tolist()\n",
    "\n",
    "# Write in a text file the  for sequences with  locus tags\n",
    "with open('locus_Dickeya_CAZy.txt', 'w') as file_handler:\n",
    "    for i in locus_tags_list:\n",
    "        file_handler.write(\"{}\\n\".format(i))\n",
    "shutil.move(\"./locus_Dickeya_CAZy.txt\", \"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/locus_Dickeya_CAZy.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/locus_Dickeya_CAZy.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-623c79cff110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"locus_Dickeya_CAZy.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"locus_Dickeya_CAZy.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/locus_Dickeya_CAZy.txt'"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data\"\n",
    "print(os.path.join(data_dir, \"locus_Dickeya_CAZy.txt\"))\n",
    "with open(os.path.join(data_dir, \"locus_Dickeya_CAZy.txt\"), 'r') as fh:\n",
    "    for line in fh:\n",
    "        line = line.strip()\n",
    "        cmd = \"python3 ./extract_rbbh.py --db dickeya.db --seqfile dickeya_cds_aa.fasta --locus_tag %s  -v -l %s.log\" %(line, line)\n",
    "        print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.system('python3 ./bin/RBBH_cazy.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('locus_Dickeya_CAZy.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        line = line.strip()\n",
    "        cmd = cmd = \"python3 ./bin/extract_rbbh.py --db  dickeya.db --seqfile dickeya_cds_aa.fasta --locus_tag %s  -v -l %s.log\" %(line,line)\n",
    "        subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make directories based on the CAZy family the enzymes with known locus tags belong to \n",
    "# Copying and moving the RBBH for the entries with more than one value making sure they exist in both families\n",
    "path = \".\"\n",
    "path_data = \"../data\"    \n",
    "cazy_locus_tags = os.path.join(path_path, \"cazy_locus_tags\") \n",
    "os.makedirs(cazy_locus_tags)   \n",
    "mydict = {}\n",
    "for x in range(len(locus_split)):\n",
    "    currentid = locus_split.iloc[x,3]\n",
    "    currentvalue = locus_split.iloc[x,5]\n",
    "    mydict.setdefault(currentid, [])\n",
    "    mydict[currentid].append(currentvalue)\n",
    "for key, value in mydict.items():\n",
    "    for i in os.listdir(path):\n",
    "        if i.endswith(\"rbbh.fasta\"):\n",
    "            #assert os.path.exists(os.path.join(path, i))\n",
    "            infstem = i.split('.',1)[0]\n",
    "            if key == infstem:\n",
    "                if len(value) > 1:\n",
    "                    value1 = value[0]\n",
    "                    value2 = value[1]\n",
    "                    string_value1 = ''.join(value1)\n",
    "                    string_value2 = ''.join(value2)\n",
    "                    dest_dir1 = os.path.join(cazy_locus_tags, string_value1)\n",
    "                    dest_dir2 = os.path.join(cazy_locus_tags, string_value2)\n",
    "                    dest_file1 = os.path.join(dest_dir1, i)\n",
    "                    dest_file2 = os.path.join(dest_dir2, i)\n",
    "                    if not os.path.exists(dest_dir1):\n",
    "                        os.makedirs(dest_dir1)\n",
    "                    if not os.path.exists(dest_dir2):\n",
    "                        os.makedirs(dest_dir2)\n",
    "                    shutil.copy(os.path.join(path_data, i), dest_file1)\n",
    "                    shutil.copy(os.path.join(path_data, i), dest_file2)\n",
    "                    \n",
    "                else:\n",
    "                    string_value = ''.join(value)\n",
    "                    dest_dir = os.path.join(path_data, string_value)\n",
    "                    dest_file = os.path.join(dest_dir, i)\n",
    "                    os.makedirs(dest_dir, exist_ok=True)\n",
    "                    if not os.path.exists(dest_file):\n",
    "                        #assert os.path.exists(os.path.join(path, i)), os.path.join(path, i)\n",
    "                           shutil.copy(os.path.join(path_data, i), dest_file)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for rbbh in os.listdir(\".f\"):\n",
    "    if rbbh.endswith(\"rbbh.fasta\") or rbbh.endswith(\".log\"):\n",
    "        os.remove(os.path.join(\"./bin\", rbbh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Keeping unique fasta sequences as RBBH ouptup grouped per CAZy family \n",
    "We now want to make sure that the file containing the RBBH outout result fasta files do not contain any duplicate sequences. We can do that by looping over all fasta files in each CAZy directory first, then adding in a list all record.id for the first file and writing those seqs in a new file named after the CAZy family. Then we chech all other fasta files stored ithin the directory for record.id which are not in the list already. If there are not in the list then we append them to the new fasta file and then append them to the list too. If are already exist in the list then we skip those sequences. \n",
    "\n",
    "Finally we apply this logic for all CAZy directories (we need to exlude a couple of directories from the process such as the result and data directories). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a directory to store all final rbbh files per CAZy family\n",
    "final_rbbh = './data/cazy_rbbh'\n",
    "os.makedirs(final_rbbh, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cazy_locus =\"./data/cazy_locus_tags/\"\n",
    "# We loop over the CAZy directories. \n",
    "for family in os.listdir(cazy_locus):\n",
    "# We create an empty list, we open the first file in the CAZy directory, we open a new fasta file to write the unique \n",
    "# sequences, and we get all records and write them to the new file. \n",
    "    seqlist = []\n",
    "    cazy_fam = os.path.join(cazy_locus, family)\n",
    "    with open(cazy_fam + \"/\" + os.listdir(cazy_fam)[0], \"r\") as f2:\n",
    "        with open(family +\".rbbh.fasta\", \"w\") as output_handle:\n",
    "            for records in SeqIO.parse(f2, \"fasta\"):\n",
    "                output_handle.write(\">\" + records.id + \"\\n\")\n",
    "                output_handle.write (str(records.seq)+ \"\\n\")               \n",
    "# We open the new fasta file in read mode and we add the seq ids \n",
    "    with open(family +'.rbbh.fasta', \"r\") as output_handle:\n",
    "        for records in SeqIO.parse(output_handle, \"fasta\"):\n",
    "            seqlist.append(records.id)\n",
    "                \n",
    "# We  open the new fasta file in append mode and we loop over the fasta files within the directory,\n",
    "# we add the sequences to the new fasta file if the record.id is not in the seqlist and once write it out then add the id\n",
    "# to the seqlist with append\n",
    "    with open(family +\".rbbh.fasta\", \"a\") as output_handle: \n",
    "        for file in os.listdir(os.path.join(cazy_locus,family)):\n",
    "            with open(cazy_fam + \"/\" + file, \"r\") as f1:\n",
    "                for record in SeqIO.parse(f1, \"fasta\"):\n",
    "                    if record.id not in seqlist:\n",
    "                        print(\"These records are new and unique: \" + record.id)\n",
    "                        output_handle.write(\">\" + record.id + \"\\n\")\n",
    "                        output_handle.write (str(record.seq)+ \"\\n\") \n",
    "                        seqlist.append(record.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for files in os.listdir(path):\n",
    "    if files.endswith(\".rbbh.fasta\"):\n",
    "        shutil.move(files, final_rbbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
